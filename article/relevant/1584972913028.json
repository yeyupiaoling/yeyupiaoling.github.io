{"relevantArticles":[{"articleTitle":"SQL格式笔记","articleAbstractText":"说明：[]内的参数可以省略 表的创建 create table &lt;表名&gt; (&lt;列名&gt; &lt;数据类型&gt; [列级完整性约束条件], &lt;列名&gt; &lt;数据类型&gt; [列级完整性约束条件], ······ ,&lt;表级完整性约束条件&gt;); 表的修改 alter table &lt;表名&gt; [add [column] &lt;新列名&gt; &lt;数据类型&gt; [完整性约束]] [add &lt;表级完整性约束&gt;] [drop [column] &lt;列名&gt; [cascade|restrict]] [drop constraint &lt;完整性约束名&gt; [restrict|cascade]] [alter column &lt;列名&gt; &lt;数据类型&gt;]; 表的删除 drop table &lt;表名&gt; [cascade|restrict]; 查询 select &lt;目标列表达式&gt; [,&lt;目标列表达式&gt;]··· from &lt;表名&gt; [group.......","articleStatus":0,"articlePermalink":"/articles/1584872767567.html","articleImg1URL":"https://b3logfile.com/bing/20171130.jpg?imageView2/1/w/1280/h/720/interlace/1/q/100"},{"articleTitle":"CentOS下安装和使用Mycat实现分布式数据库","articleAbstractText":"前言 在笔者的《在CentOS上使用Nginx和Tomcat搭建高可用高并发网站》这篇文章中，笔者介绍了如何在CentOS上搭建一个可支持高可用高并发的Java web后端服务器。善于思考的读者可能会想到，在上一篇文章中，我们只是实现Java web服务器的分布式来应对高并发，但是高并发对数据库的的负担也是很重的。在上一篇文章中，我们只是使用到一个MySQL服务器，但是但数据量非常大的时候，比如有一千万的用户，如果只有单个数据库存储，那一张用户表就有一千万条数据。庞大的数据量使得我们对数据进行查询的时候非常慢，但出现高并发的时候，大量的查询请求发送到数据库服务器，而数据库来不及响应，随时可能出现数据库崩溃的情况。 面对这个问题，我们使用Mycat来实现分布式数据库，假设我们有两个数据库服务器，那么一千万条的数据分开来存储，这样每个数据库只有五百万条数据，可以大大提高查询速度。如果有更多的数据库服务器，那么每个数据库所需要存储的数据就更少了，查询速度就会更快。基于这一个问题，我们就来学习如何在CentOS下安装和使用Mycat实现分布式数据库。 分布式数据库的整体架构： 总体架构 我们.....","articleStatus":0,"articlePermalink":"/articles/1584972765438.html","articleImg1URL":"https://img.hacpai.com/bing/20190709.jpg?imageView2/1/w/960/h/540/interlace/1/q/100"},{"articleTitle":"MySQL数据库实现主从复制","articleAbstractText":"前言 我们用的在这篇文章《在CentOS上使用Nginx和Tomcat搭建高可用高并发网站》使用的只有一个MySQL数据库。 从安全角度来说这是非常不安全的，比如这个数据库服务器磁盘突然损坏了，里面的数据全部丢失了。这种情况如果一开始只是部署一个数据库的话就非常危险了，这表明我们要丢失全部数据，而数据对网站来说是最最重要的，所以我们要保证数据的安全。 从性能上来说，我们在《CentOS下安装和使用Mycat实现分布式数据库》这篇文章中介绍了分布式数据库，性能虽然比单个数据库的性能要好。但是当使用分布式数据库时，数据量还是很大，在查询数据时，可能会变得非常慢，导致锁表，一旦锁表就无法写入数据，就会影响其他用户的写入数据的操做。所以就需要读写分离，主（master）数据库负责写入数据，从（slave）数据库负责查询数据，就算从（slave）数据库在查询数据时出现了锁表，也不会影响到主（master）数据库的的写入操作，最多也是从（slave）数据库的数据更新的慢一些。基于这种情况，就出现了主从复制这个技术。 **主从复制：**就是有两个数据库服务器，一个是主（master）数据库服务器......","articleStatus":0,"articlePermalink":"/articles/1584972836923.html","articleImg1URL":"https://img.hacpai.com/bing/20180612.jpg?imageView2/1/w/960/h/540/interlace/1/q/100"},{"articleTitle":"XAMPP下的MYSQL解决中文乱码问题","articleAbstractText":"相信有很多朋友都跟我一样，使用XAMPP集成的MYSQL，因为它操作起来实在太方便了。但是它默认不是支持UTF-8的，需要我们手动去修改配置文件 my.ini 打开XAMPP的控制面板，并打开配置文件 在配置文件上加上4句话 default_character_set = utf8 character-set-server = utf8 collation-server = utf8_general_ci default_character_set = utf8 第1句： default_character_set = utf8 第2句和第3句 character-set-server = utf8 collation-server = utf8_general_ci 第4句： default_character_set = utf8 重启一下MySQL就行了，你重新创建一个数据库看看，但是数据库的编码一定要选对 说到这里顺便提一下Ubuntu server的MySQL中文乱码问题 在Ubuntu中配置文件的路径有点不一样，配置文件的内容也不一样，以下是路径 用vi....","articleStatus":0,"articlePermalink":"/articles/1584872438296.html","articleImg1URL":"https://img.hacpai.com/bing/20200206.jpg?imageView2/1/w/960/h/540/interlace/1/q/100"},{"articleTitle":"《PaddlePaddle从入门到炼丹》十四\u2014\u2014把预测模型部署在服务器","articleAbstractText":"GitHub地址：https://github.com/yeyupiaoling/LearnPaddle2/tree/master/note14 前言 如果读者使用过百度等的一些图像识别的接口，比如百度的细粒度图像识别接口，应该了解这个过程，省略其他的安全方面的考虑。这个接口大体的流程是，我们把图像上传到百度的网站上，然后服务器把这些图像转换成功矢量数据，最后就是拿这些数据传给深度学习的预测接口，比如是PaddlePaddle的预测接口，获取到预测结果，返回给客户端。这个只是简单的流程，真实的复杂性远远不止这些，但是我们只需要了解这些，然后去搭建属于我们的图像识别接口。 了解Flask 安装flask很简单，只要一条命令就可以了： pip install flask 同时我们也使用到flask_cors，所以我们也要安装这个库 pip install flask_cors 创建一个 paddle_server.py文件，然后编写一个简单的程序，了解一些如何使用这个Flask框架，首先导入所需的依赖库： import os import uuid import numpy as np......","articleStatus":0,"articlePermalink":"/articles/1584975208040.html","articleImg1URL":"https://img.hacpai.com/bing/20171108.jpg?imageView2/1/w/960/h/540/interlace/1/q/100"}]}