<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"/><meta name="theme-color" content="#3b3e43"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=no"/><title>基于PaddlePaddle实现的密度估计模型CrowdNet - 夜雨飘零</title><meta name="description" content="CrowdNet模型是2016年提出的人流密度估计模型，论文为《CrowdNet: A Deep Convolutional Network for DenseCrowd Counting》，CrowdNet模型主要有深层卷积神经网络和浅层卷积神经组成，通过输入原始图像和高斯滤波器得到的密度图进行训练，最终得到的模型估计图像中的行人的数量。当然这不仅仅可以用于人流密度估计，理论上其他的动物等等的密度估计应该也可以。"/><meta property="og:description" content="CrowdNet模型是2016年提出的人流密度估计模型，论文为《CrowdNet: A Deep Convolutional Network for DenseCrowd Counting》，CrowdNet模型主要有深层卷积神经网络和浅层卷积神经组成，通过输入原始图像和高斯滤波器得到的密度图进行训练，最终得到的模型估计图像中的行人的数量。当然这不仅仅可以用于人流密度估计，理论上其他的动物等等的密度估计应该也可以。"/>    <meta name="keywords" content="夜雨飘零,PaddlePaddle,Pytorch,yeyupiaoling"/><link rel="dns-prefetch" href="https://yeyupiaoling.github.io"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://yeyupiaoling.github.io"><link rel="icon" type="image/png" href="https://s1.ax1x.com/2020/03/28/GFfl6J.png"/><link rel="apple-touch-icon" href="https://s1.ax1x.com/2020/03/28/GFfl6J.png"><link rel="shortcut icon" type="image/x-icon" href="https://s1.ax1x.com/2020/03/28/GFfl6J.png"><meta name="copyright" content="B3log"/><meta http-equiv="Window-target" content="_top"/><meta property="og:locale" content="zh_CN"/><meta property="og:title" content="基于PaddlePaddle实现的密度估计模型CrowdNet - 夜雨飘零"/><meta property="og:site_name" content="夜雨飘零"/><meta property="og:url"      content="https://yeyupiaoling.github.io/articles/1642598447430.html?"/><meta property="og:image" content="https://s1.ax1x.com/2020/03/28/GFfl6J.png"/><link rel="search" type="application/opensearchdescription+xml" title="基于PaddlePaddle实现的密度估计模型CrowdNet - 夜雨飘零" href="/opensearch.xml"><link href="https://yeyupiaoling.github.io/rss.xml" title="RSS" type="application/rss+xml" rel="alternate"/><link rel="manifest" href="https://yeyupiaoling.github.io/manifest.json">        <link rel="canonical" href="https://yeyupiaoling.github.io/articles/1642598447430.html">        <link rel="stylesheet"
              href="https://yeyupiaoling.github.io/skins/yilia/css/base.css?1642833606409"/>
            <link rel="prev" title="基于PaddlePaddle实现的目标检测模型SSD" href="https://yeyupiaoling.github.io/articles/1642598329432.html">
            <link rel="next" title="Mediapipe框架在Android上的使用" href="https://yeyupiaoling.github.io/articles/1642599466593.html">
    <!-- 百度统计 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?323b22cab8431af3867539dfaf5f12f1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

<!-- 百度搜索 -->
<meta name="baidu-site-verification" content="hUGUF8EtyO" />

<!-- 百度搜索推送 -->
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script><script src="https://cdn.jsdelivr.net/npm/vditor@3.8.4/dist/js/icons/ant.js" async="" id="vditorIconScript"></script></head>
<body>
<div class="side fn__flex-column">
    <div class="overlay">
        <a onclick="$('.side .toc').show()" href="javascript:void(0)" class="toc-btn">目录</a>
    </div>
    <header class="content fn__flex-1">
        <a href="https://yeyupiaoling.github.io">
            <img class="avatar" src="https://b3logfile.com/avatar/1584446294285_1585209594823.png?imageView2/1/w/128/h/128/interlace/0/q/100" title="" alt=""/>
        </a>
        <hgroup>
            <h1>
                <a href="https://yeyupiaoling.github.io">夜雨飘零</a>
            </h1>
        </hgroup>
        <p class="subtitle">
            记录精彩的程序人生
        </p>
        <nav>
            <ul>
                    <li>
                        <a href="http://localhost:8080/tags/Pytorch" target="_blank">Pytorch系列教程</a>
                    </li>
                    <li>
                        <a href="http://localhost:8080/tags/PaddlePaddle" target="_blank">PaddlePaddle系列教程</a>
                    </li>
                <li>
                    <a href="https://yeyupiaoling.github.io/tags.html">标签墙</a>
                    &nbsp; &nbsp;
                    <a href="https://yeyupiaoling.github.io/archives.html">存档</a>
                </li>
            </ul>
        </nav>
    </header>
    <footer>
            <div class="vditor-reset">寒江孤影,江湖故人,<br/>相逢何必曾相识.

<!-- 公告栏可使用 HTML、JavaScript，比如可以在此加入第三方统计 js -->

<!-- 百度统计 -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?323b22cab8431af3867539dfaf5f12f1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
</div>
    </footer>
        <div class="toc">
            <a onclick="$('.side .toc').hide();" href="javascript:void(0)" class="close">X</a>
<ul class="article__toc">
        <li class="toc__h1">
            <a href="#toc_h1_0">前言</a>
        </li>
        <li class="toc__h1">
            <a href="#toc_h1_1">CrowdNet模型实现</a>
        </li>
        <li class="toc__h1">
            <a href="#toc_h1_2">训练模型</a>
        </li>
        <li class="toc__h2">
            <a href="#toc_h2_3">训练程序</a>
        </li>
        <li class="toc__h1">
            <a href="#toc_h1_4">预测</a>
        </li>
</ul>        </div>
</div>
<main>
    <article class="post">
        <header class="fn__flex">
            <h2 class="fn__flex-1">
                <a rel="bookmark" href="https://yeyupiaoling.github.io/articles/1642598447430.html">
                    基于PaddlePaddle实现的密度估计模型CrowdNet
                </a>
            </h2>
            <time><span class="icon-date"></span> 2022-01-22</time>
        </header>
        <div class="article__footer fn__flex">
            <span class="icon-tag fn__flex-center"></span>
            <span>&nbsp;&nbsp;&nbsp;</span>
            <div class="tags fn__flex-1 fn__flex-center">
                    <a class="tag" rel="tag" href="https://yeyupiaoling.github.io/tags/PaddlePaddle">
                        PaddlePaddle</a>
                    <a class="tag" rel="tag" href="https://yeyupiaoling.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">
                        深度学习</a>
            </div>
            <span>&nbsp;&nbsp;&nbsp;</span>
                <a href="https://yeyupiaoling.github.io/articles/1642598447430.html#b3logsolocomments"
                   class="vditor-tooltipped__n vditor-tooltipped link fn__flex-center"
                   aria-label="评论">
                    <span data-uvstatcmt="1642598447430">0</span>
                    <span class="icon-chat"></span>
                </a>
            <a class="vditor-tooltipped__n vditor-tooltipped link fn__flex-center"
               href="https://yeyupiaoling.github.io/articles/1642598447430.html"
               aria-label="浏览">
                <span data-uvstaturl="https://yeyupiaoling.github.io/articles/1642598447430.html">0</span>
                <span class="icon-views"></span>
            </a>
            <a rel="nofollow" href="https://yeyupiaoling.github.io/authors/1641912711535" class="fn__flex-center">
                <img class="avatar" title="yeyupiaoling" alt="yeyupiaoling"
                     src="https://b3logfile.com/avatar/1584446294285_1585209594823.png?imageView2/1/w/128/h/128/interlace/0/q/100"/>
            </a>
        </div>

        <section class="abstract vditor-reset">
            <p><img src="https://b3logfile.com/bing/20210316.jpg?imageView2/1/w/960/h/540/interlace/1/q/100" alt=""></p>
<h1 id="toc_h1_0">前言</h1>
<p>CrowdNet模型是2016年提出的人流密度估计模型，论文为《CrowdNet: A Deep Convolutional Network for DenseCrowd Counting》，CrowdNet模型主要有深层卷积神经网络和浅层卷积神经组成，通过输入原始图像和高斯滤波器得到的密度图进行训练，最终得到的模型估计图像中的行人的数量。当然这不仅仅可以用于人流密度估计，理论上其他的动物等等的密度估计应该也可以。</p>
<p><strong>项目开源地址：</strong> <a href="https://github.com/yeyupiaoling/PaddlePaddle-CrowdNet.git" target="_blank">https://github.com/yeyupiaoling/PaddlePaddle-CrowdNet.git</a></p>
<p>本项目开发环境为：</p>
<ul>
<li>Windows 10</li>
<li>Python 3.7</li>
<li>PaddlePaddle 2.0.0a0</li>
</ul>
<h1 id="toc_h1_1">CrowdNet模型实现</h1>
<p>以下是CrowdNet模型的结构图，从结构图中可以看出，CrowdNet模型是深层卷积网络（Deep Network）和浅层卷积网络（Shallow Network）组成，两组网络通过拼接成一个网络，接着输入到一个卷积核数量和大小都是1的卷积层，最后通过插值方式得到一个密度图数据，通过统计这个密度就可以得到估计人数<br>
<img src="https://b3logfile.com/file/2022/01/solo-fetchupload-7298287634308570671-88a53bec.jpeg?imageView2/2/w/1280/format/jpg/interlace/1/q/100" alt="在这里插入图片描述"></p>
<p>在PaddlePaddle中，通过以下代码判断即可实现上面的CrowdNet模型，在深层卷积网络和浅层卷积网络的卷积层都使用conv_bn卷积层，这个是通过把卷积层和batch_norm组合在一起的。在本项目中，输入的图像大小[3, 640, 480]，密度图大小为[1, 80, 60]，所以深层卷积网络输出的shape为[512, 80, 60]，浅层神经网络的输出为[24, 80, 60]。两个网络的输出通过<code>fluid.layers.concat()</code>接口进行拼接，拼接后输入到<code>fluid.layers.conv2d()</code>，最后通过<code>fluid.layers.resize_bilinear()</code> 双向性插值法输出一个密度图，最后使用的<code>fluid.layers.reduce_sum()</code>是为了方便在预测时直接输出估计人数。</p>
<pre><code class="language-python">def deep_network(img):
    x = img
    x = conv_bn(input=x, num_filters=64, filter_size=3, padding=1, act='relu')
    x = conv_bn(input=x, num_filters=64, filter_size=3, padding=1, act='relu')
    x = fluid.layers.pool2d(input=x, pool_size=2, pool_stride=2)
    x = fluid.layers.dropout(x=x, dropout_prob=0.25)
    x = conv_bn(input=x, num_filters=128, filter_size=3, padding=1, act='relu')
    x = conv_bn(input=x, num_filters=128, filter_size=3, padding=1, act='relu')
    x = fluid.layers.pool2d(input=x, pool_size=2, pool_stride=2)
    x = fluid.layers.dropout(x=x, dropout_prob=0.25)
    x = conv_bn(input=x, num_filters=256, filter_size=3, padding=1, act='relu')
    x = conv_bn(input=x, num_filters=256, filter_size=3, padding=1, act='relu')
    x = conv_bn(input=x, num_filters=256, filter_size=3, padding=1, act='relu')
    x = fluid.layers.pool2d(input=x, pool_size=2, pool_stride=2)
    x = fluid.layers.dropout(x=x, dropout_prob=0.5)
    x = conv_bn(input=x, num_filters=512, filter_size=3, padding=1, act='relu')
    x = conv_bn(input=x, num_filters=512, filter_size=3, padding=1, act='relu')
    x = conv_bn(input=x, num_filters=512, filter_size=3, padding=1, act='relu')
    x = fluid.layers.pool2d(input=x, pool_size=3, pool_stride=1, pool_padding=1)
    x = conv_bn(input=x, num_filters=512, filter_size=3, padding=1, act='relu')
    x = conv_bn(input=x, num_filters=512, filter_size=3, padding=1, act='relu')
    x = conv_bn(input=x, num_filters=512, filter_size=3, padding=1)
    x = fluid.layers.dropout(x=x, dropout_prob=0.5)
    return x


def shallow_network(img):
    x = img
    x = conv_bn(input=x, num_filters=24, filter_size=5, padding=3, act='relu')
    x = fluid.layers.pool2d(input=x, pool_size=5, pool_type='avg', pool_stride=2)
    x = conv_bn(input=x, num_filters=24, filter_size=5, padding=3, act='relu')
    x = fluid.layers.pool2d(input=x, pool_size=5, pool_type='avg', pool_stride=2)
    x = conv_bn(input=x, num_filters=24, filter_size=5, padding=4, act='relu')
    x = fluid.layers.pool2d(input=x, pool_size=5, pool_type='avg', pool_stride=2)
    return x

# 创建CrowdNet网络模型
net_out1 = deep_network(images)
net_out2 = shallow_network(images)
concat_out = fluid.layers.concat([net_out1, net_out2], axis=1)
conv_end = fluid.layers.conv2d(input=concat_out, num_filters=1, filter_size=1)
# 双向性插值
map_out = fluid.layers.resize_bilinear(conv_end, out_shape=(80, 60))
# 避开Batch维度求和
sum_ = fluid.layers.reduce_sum(map_out, dim=[1, 2, 3])
sum_ = fluid.layers.reshape(sum_, [-1, 1])
</code></pre>
<p>通过上面实现的CrowdNet模型，它的结构如下图所示：<br>
<img src="https://b3logfile.com/file/2022/01/solo-fetchupload-1733316244311350729-56c08926.png?imageView2/2/w/1280/format/jpg/interlace/1/q/100" alt="在这里插入图片描述"></p>
<h1 id="toc_h1_2">训练模型</h1>
<p>本项目使用的是百度公开的一个人流密度数据集，数据集下载链接：<a href="https://aistudio.baidu.com/aistudio/datasetdetail/1917" target="_blank">https://aistudio.baidu.com/aistudio/datasetdetail/1917</a>，下载之后，执行下面操作：</p>
<ul>
<li>把<code>train.json</code>文件存放在<code>data</code>目录</li>
<li>把<code>test_new.zip</code>解压到<code>data</code>目录</li>
<li>把<code>train_new.zip</code>解压到<code>data</code>目录</li>
</ul>
<p>本项目提供了一个脚本<code>create_list.py</code>可以把百度公开的数据集数据标准文件生成本项目所需要的标注格式，通过执行脚本可以生成类似以下格式的数据列表，每一行的前面是图像路径，后面的是人的坐标点，中间用制表符<code>\t</code>分开。如果开发者要训练自己的数据集，将图像标注数据生成以下格式即可。</p>
<pre><code>data/train/4c93da45f7dc854a31a4f75b1ee30056.jpg	[(171, 200), (365, 144), (306, 155), (451, 204), (436, 252), (600, 235)]
data/train/3a8c1ed636145f23e2c5eafce3863bb2.jpg	[(788, 205), (408, 250), (115, 233), (160, 261), (226, 225), (329, 161)]
data/train/075ed038030094f43f5e7b902d41d223.jpg	[(892, 646), (826, 763), (845, 75), (896, 260), (773, 752)]
</code></pre>
<p>模型的输入标签是一个密度图，那么如何通过标注数据生成一个密度图的，下面就来简单介绍一下。其实就是一些不同核的高斯滤波器生成的，得到的一个比输入图像小8倍的密度图。</p>
<pre><code class="language-python">import json
import numpy as np
import scipy
from PIL import Image
import matplotlib.pyplot as plt
from matplotlib import cm as CM
import scipy
import scipy.spatial
from PIL import Image
from scipy.ndimage.filters import gaussian_filter
import os

# 图片预处理
def picture_opt(img, ann):
    # 缩放的图像大小
    train_img_size = (640, 480)
    gt = []
    size_x, size_y = img.size
    img = img.resize(train_img_size, Image.ANTIALIAS)

    for b_l in range(len(ann)):
        x = ann[b_l][0]
        y = ann[b_l][1]
        x = (x * train_img_size[0] / size_x) / 8
        y = (y * train_img_size[1] / size_y) / 8
        gt.append((x, y))

    img = np.array(img) / 255.0
    return img, gt

# 高斯滤波
def gaussian_filter_density(gt):
    density = np.zeros(gt.shape, dtype=np.float32)
    gt_count = np.count_nonzero(gt)
    if gt_count == 0:
        return density
    pts = np.array(list(zip(np.nonzero(gt)[1].ravel(), np.nonzero(gt)[0].ravel())))
    tree = scipy.spatial.KDTree(pts.copy(), leafsize=2048)
    distances, locations = tree.query(pts, k=4)
    for i, pt in enumerate(pts):
        pt2d = np.zeros(gt.shape, dtype=np.float32)
        pt2d[pt[1], pt[0]] = 1.
        if gt_count &gt; 1:
            sigma = (distances[i][1] + distances[i][2] + distances[i][3]) * 0.1
        else:
            sigma = np.average(np.array(gt.shape)) / 2. / 2.
        density += scipy.ndimage.filters.gaussian_filter(pt2d, sigma, mode='constant')
    return density


# 密度图处理
def ground(img, gt):
    imgs = img
    x = imgs.shape[0] / 8
    y = imgs.shape[1] / 8
    k = np.zeros((int(x), int(y)))
    for i in range(0, len(gt)):
        if int(gt[i][1]) &lt; int(x) and int(gt[i][0]) &lt; int(y):
            k[int(gt[i][1]), int(gt[i][0])] = 1
    img_sum = np.sum(k)
    k = gaussian_filter_density(k)
    return k, img_sum
</code></pre>
<p>读取一张图片，并经过缩放预处理，在这里图像没有经过装置，但是在训练过程中需要对图像执行装置<code>im.transpose()</code>操作，这样才符合PaddlePaddle的输入格式。</p>
<pre><code class="language-python"># 读取数据列表
with open('data/data_list.txt', 'r', encoding='utf-8') as f:
    lines = f.readlines()

line = lines[50]
img_path, gt = line.replace('\n', '').split('\t')
gt = eval(gt)
img = Image.open(img_path)
im, gt = picture_opt(img, gt)

print(im.shape)
plt.imshow(im)
</code></pre>
<p><img src="https://b3logfile.com/file/2022/01/solo-fetchupload-837686940226248404-283b15e5.png?imageView2/2/w/1280/format/jpg/interlace/1/q/100" alt="在这里插入图片描述"><br>
通过<code>ground()</code>函数将上面的图片生成一个密度图，密度图结果如下图所示。注意在输入PaddlePaddle的密度图是要经过装置的，因为图像的数据的输入是装置的，所以密度图也得装置。</p>
<pre><code class="language-python">k, img_sum = ground(im, gt)
groundtruth = np.asarray(k)
groundtruth = groundtruth.astype('float32')

print("实际人数：", img_sum)
print("密度图人数：", np.sum(groundtruth))
print("密度图大小：", groundtruth.shape)

plt.imshow(groundtruth,cmap=CM.jet)
</code></pre>
<p><img src="https://b3logfile.com/file/2022/01/solo-fetchupload-10048557907784152338-5c33a3cf.png?imageView2/2/w/1280/format/jpg/interlace/1/q/100" alt="在这里插入图片描述"></p>
<h2 id="toc_h2_3">训练程序</h2>
<p>以下为<code>train.py</code>的代码，在训练中使用了平方差损失函数，其中损失值乘以<code>6e5</code>是为了不让输出的损失值太小。</p>
<pre><code class="language-python">loss = fluid.layers.square_error_cost(input=map_out, label=label) * 6e5
loss = fluid.layers.mean(loss)
</code></pre>
<p>为了加快数据的读取，这里使用了异步数据读取方式，可以一边训练一边读取下一步batch的数据。</p>
<pre><code class="language-python">py_reader = fluid.io.PyReader(feed_list=[images, label, img_num],
                              capacity=32,
                              iterable=True,
                              return_list=False)
py_reader.decorate_sample_list_generator(paddle.batch(reader.train_reader(data_list_file), batch_size=BATCH_SIZE),
                                         places=fluid.core.CPUPlace())
</code></pre>
<p>在训练前加上一个加载预训练模型的方法，如果之前的模型存在，就加载该模型，接着上一次的训练结果继续训练。</p>
<pre><code class="language-python">if PERSISTABLES_MODEL_PATH is not None and os.path.exists(PERSISTABLES_MODEL_PATH):
    def if_exist(var):
        if os.path.exists(os.path.join(PERSISTABLES_MODEL_PATH, var.name)):
            print('loaded: %s' % var.name)
        return os.path.exists(os.path.join(PERSISTABLES_MODEL_PATH, var.name))


    fluid.io.load_vars(exe, PERSISTABLES_MODEL_PATH, main_program=fluid.default_main_program(), predicate=if_exist)
</code></pre>
<p>在执行训练前需要留意以下几个参数，需要根据自己的实际情况修改。当然如果开发者都是按照上面的操作，这里基本上不需要修改，但是<code>BATCH_SIZE</code>可能要修改一下，因为这个模型比较大，如何显存小的可能还有修改，以下是笔者在8G显存的环境下设置的。</p>
<pre><code class="language-python"># 是否使用GPU
USE_CUDA = True
# 模型参数保存路径
PERSISTABLES_MODEL_PATH = 'persistables_model/'
# 预测模型保存路径
INFER_MODEL = 'infer_model/'
# 训练轮数
EPOCHS_SUM = 800
# Batch大小
BATCH_SIZE = 6
# 图像列表路径
data_list_file = 'data/data_list.txt'
</code></pre>
<p>最后执行<code>python train.py</code>开始训练模型。</p>
<h1 id="toc_h1_4">预测</h1>
<p>最通过执行<code>infer.py</code>可以把<code>data/test/</code>目录下的图像都进行预测，结果写入到<code>results.csv</code>文件中。</p>
<p>下面介绍预测的大概方式，通过加载训练过程中保存的预测模型，得到一个预测程序。</p>
<pre><code class="language-python">import matplotlib.pyplot as plt
from matplotlib import cm as CM
import os
import numpy as np
import paddle.fluid as fluid
from PIL import Image

# 是否使用GPU
USE_CUDA = True
INFER_MODEL = 'infer_model/'

place = fluid.CUDAPlace(0) if USE_CUDA else fluid.CPUPlace()
exe = fluid.Executor(place)

[inference_program,
 feed_target_names,
 fetch_targets] = fluid.io.load_inference_model(INFER_MODEL, exe)
</code></pre>
<p>读取一张待预测的图片。</p>
<pre><code class="language-python">image_path = "data/test/00bdc7546131db72333c3e0ac9cf5478.jpg"
test_img = Image.open(image_path)
plt.imshow(test_img)
</code></pre>
<p><img src="https://b3logfile.com/file/2022/01/solo-fetchupload-23021468184710057-64aa3710.png?imageView2/2/w/1280/format/jpg/interlace/1/q/100" alt="在这里插入图片描述"></p>
<p>通过对图像进行预处理，输入到预测程序中，预测的结果有两个，第一个是密度图，第二个是估计人数，因为输出的估计是估计人数是一个带小数的值，所以要进行四舍五入。其实对密度图求和也是能够得到估计人数的。因为PaddlePaddle输出的密度图是经过转置的，所以在显示时需要再一次执行转置才能正常显示。</p>
<pre><code class="language-python">test_img = test_img.resize((640, 480), Image.ANTIALIAS)
test_im = np.array(test_img) / 255.0
test_im = test_im.transpose().reshape(1, 3, 640, 480).astype('float32')

results = exe.run(program=inference_program,
                    feed={feed_target_names[0]: test_im},
                    fetch_list=fetch_targets)
density, quantity = results[0], results[1]
q = int(abs(quantity) + 0.5)

print("预测人数：", q)
plt.imshow(density[0][0].T,cmap=CM.jet)
</code></pre>
<p><img src="https://b3logfile.com/file/2022/01/solo-fetchupload-15561846675301795728-0beef9da.png?imageView2/2/w/1280/format/jpg/interlace/1/q/100" alt="在这里插入图片描述"></p>
                <div>
                    <hr>

标题：基于PaddlePaddle实现的密度估计模型CrowdNet<br>
作者：<a href="https://yeyupiaoling.github.io" target="_blank">yeyupiaoling</a><br>
地址：<a href="https://yeyupiaoling.github.io/articles/1642598447430.html" target="_blank">https://yeyupiaoling.github.io/articles/1642598447430.html</a><br>

<!-- 签名档内可使用 HTML、JavaScript -->
<br>
                </div>

                <aside class="fn__flex">
                        <a class="fn__flex-1 fn__flex-inline" rel="prev" href="https://yeyupiaoling.github.io/articles/1642598329432.html">
                            <strong>&lt;</strong>
                            <span>&nbsp; 基于PaddlePaddle实现的目标检测模型SSD&nbsp;&nbsp;&nbsp;</span>
                        </a>
                        <a class="fn__flex-inline" rel="next" href="https://yeyupiaoling.github.io/articles/1642599466593.html">
                            <span>Mediapipe框架在Android上的使用&nbsp; </span>
                            <strong>&gt;</strong>
                        </a>
                </aside>
        </section>

        <footer class="fn-clear share">
            <div class="fn-right">
<div class="article__share"
     data-title="基于PaddlePaddle实现的密度估计模型CrowdNet"
     data-blogtitle="夜雨飘零"
     data-url="https://yeyupiaoling.github.io/articles/1642598447430.html"
     data-avatar="https://b3logfile.com/avatar/1584446294285_1585209594823.png?imageView2/1/w/128/h/128/interlace/0/q/100">
    <span class="item" data-type="qqz">
        <svg viewBox="0 0 32 32" width="100%" height="100%">
            <path d="M22.824 13.989l-8.348 6.287s3.351 0.522 8.404 0.461l-0.23-1.040 7.2-6.549c0.132-0.12 0.183-0.312 0.129-0.487s-0.203-0.299-0.377-0.314l-9.492-0.856-3.708-9.213c-0.068-0.169-0.226-0.279-0.401-0.279s-0.333 0.11-0.401 0.279l-3.708 9.213-9.492 0.856c-0.174 0.015-0.323 0.139-0.377 0.314s-0.004 0.366 0.129 0.487l7.2 6.549-2.158 9.742c-0.040 0.178 0.026 0.365 0.168 0.474 0.142 0.107 0.331 0.115 0.481 0.021l8.158-5.165 8.158 5.165c0.070 0.045 0.147 0.066 0.225 0.066 0.090 0 0.18-0.029 0.256-0.086 0.142-0.109 0.208-0.295 0.168-0.474l-1.707-7.704c0.732-0.386 1.538-1.040 1.538-1.040s-3.195 1.638-14.664 0.838l8.312-6.325s-0.327-0.534-10.744-0.914c-0.697-0.026 8.493-1.83 15.281-0.305z"></path>
        </svg>
    </span>
    <span class="item" data-type="wechat">
        <svg viewBox="0 0 32 32" width="100%" height="100%">
            <path d="M9.062 9.203c0-0.859-0.562-1.422-1.422-1.422-0.844 0-1.703 0.562-1.703 1.422 0 0.844 0.859 1.406 1.703 1.406 0.859 0 1.422-0.562 1.422-1.406zM20.672 17.125c0-0.562-0.562-1.125-1.422-1.125-0.562 0-1.125 0.562-1.125 1.125 0 0.578 0.562 1.141 1.125 1.141 0.859 0 1.422-0.562 1.422-1.141zM16.984 9.203c0-0.859-0.562-1.422-1.406-1.422-0.859 0-1.703 0.562-1.703 1.422 0 0.844 0.844 1.406 1.703 1.406 0.844 0 1.406-0.562 1.406-1.406zM26.906 17.125c0-0.562-0.578-1.125-1.422-1.125-0.562 0-1.125 0.562-1.125 1.125 0 0.578 0.562 1.141 1.125 1.141 0.844 0 1.422-0.562 1.422-1.141zM22.75 10.922c-0.359-0.047-0.719-0.063-1.094-0.063-5.375 0-9.625 4.016-9.625 8.953 0 0.828 0.125 1.625 0.359 2.375-0.359 0.031-0.703 0.047-1.063 0.047-1.422 0-2.547-0.281-3.969-0.562l-3.953 1.984 1.125-3.406c-2.828-1.984-4.531-4.547-4.531-7.656 0-5.391 5.094-9.625 11.328-9.625 5.563 0 10.453 3.391 11.422 7.953zM32 19.687c0 2.547-1.688 4.813-3.969 6.516l0.859 2.828-3.109-1.703c-1.141 0.281-2.281 0.578-3.406 0.578-5.391 0-9.625-3.688-9.625-8.219s4.234-8.219 9.625-8.219c5.094 0 9.625 3.688 9.625 8.219z"></path>
        </svg>
    </span>
    <span class="item" data-type="weibo">
        <svg viewBox="0 0 32 32" width="100%" height="100%">
            <path d="M13.444 27.064c-5.3 0.525-9.875-1.875-10.219-5.35-0.344-3.481 3.675-6.719 8.969-7.244 5.3-0.525 9.875 1.875 10.212 5.35 0.35 3.481-3.669 6.725-8.963 7.244zM24.038 15.521c-0.45-0.137-0.762-0.225-0.525-0.819 0.512-1.287 0.563-2.394 0.006-3.188-1.038-1.481-3.881-1.406-7.137-0.037 0 0-1.025 0.444-0.762-0.363 0.5-1.613 0.425-2.956-0.356-3.737-1.769-1.769-6.469 0.069-10.5 4.1-3.013 3.006-4.763 6.212-4.763 8.981 0 5.287 6.787 8.506 13.425 8.506 8.7 0 14.494-5.056 14.494-9.069 0-2.431-2.044-3.806-3.881-4.375z"></path>
            <path d="M29.819 5.833c-2.1-2.331-5.2-3.219-8.063-2.612v0c-0.663 0.144-1.081 0.794-0.938 1.45 0.144 0.662 0.788 1.081 1.45 0.938 2.038-0.431 4.238 0.2 5.731 1.856s1.9 3.913 1.256 5.888v0c-0.206 0.644 0.144 1.331 0.788 1.544 0.644 0.206 1.331-0.144 1.544-0.787v-0.006c0.9-2.762 0.331-5.938-1.769-8.269z"></path>
            <path d="M26.588 8.752c-1.025-1.138-2.538-1.569-3.925-1.269-0.569 0.119-0.931 0.688-0.813 1.256 0.125 0.569 0.688 0.931 1.25 0.806v0c0.681-0.144 1.419 0.069 1.919 0.619 0.5 0.556 0.637 1.313 0.419 1.975v0c-0.175 0.55 0.125 1.15 0.681 1.331 0.556 0.175 1.15-0.125 1.331-0.681 0.438-1.356 0.163-2.906-0.863-4.037z"></path>
            <path d="M13.738 20.771c-0.188 0.319-0.594 0.469-0.912 0.337-0.319-0.125-0.412-0.488-0.231-0.794 0.188-0.306 0.581-0.456 0.894-0.337 0.313 0.113 0.425 0.469 0.25 0.794zM12.044 22.933c-0.512 0.819-1.613 1.175-2.438 0.8-0.813-0.369-1.056-1.319-0.544-2.119 0.506-0.794 1.569-1.15 2.388-0.806 0.831 0.356 1.1 1.3 0.594 2.125zM13.969 17.146c-2.519-0.656-5.369 0.6-6.463 2.819-1.119 2.262-0.037 4.781 2.506 5.606 2.638 0.85 5.75-0.456 6.831-2.894 1.069-2.394-0.262-4.85-2.875-5.531z"></path>
        </svg>
    </span>
    <span class="item" data-type="twitter">
        <svg viewBox="0 0 32 32" width="100%" height="100%">
            <path d="M32.003 6.075c-1.175 0.525-2.444 0.875-3.769 1.031 1.356-0.813 2.394-2.1 2.887-3.631-1.269 0.75-2.675 1.3-4.169 1.594-1.2-1.275-2.906-2.069-4.794-2.069-3.625 0-6.563 2.938-6.563 6.563 0 0.512 0.056 1.012 0.169 1.494-5.456-0.275-10.294-2.888-13.531-6.862-0.563 0.969-0.887 2.1-0.887 3.3 0 2.275 1.156 4.287 2.919 5.463-1.075-0.031-2.087-0.331-2.975-0.819 0 0.025 0 0.056 0 0.081 0 3.181 2.263 5.838 5.269 6.437-0.55 0.15-1.131 0.231-1.731 0.231-0.425 0-0.831-0.044-1.237-0.119 0.838 2.606 3.263 4.506 6.131 4.563-2.25 1.762-5.075 2.813-8.156 2.813-0.531 0-1.050-0.031-1.569-0.094 2.913 1.869 6.362 2.95 10.069 2.95 12.075 0 18.681-10.006 18.681-18.681 0-0.287-0.006-0.569-0.019-0.85 1.281-0.919 2.394-2.075 3.275-3.394z"></path>
        </svg>
    </span>
    <span class="item__qr"></span>
</div>            </div>
        </footer>
            <div id="relevantArticles" class="abstract"></div>
            <div id="randomArticles" class="abstract"></div>
        <br>
    </article>
        <div style="padding: 30px 60px 30px 50px;" id="gitalk-container"></div>
        <div id="b3logsolocomments"></div>
        <div id="vcomment" style="padding: 30px 60px 30px 50px;" data-name="yeyupiaoling"
             data-postId="1642598447430"></div>

<footer class="footer">
    <div class="fn-clear">
        浏览数：<span data-uvstaturl="https://yeyupiaoling.github.io">0</span>
        &nbsp;
        文章总数：120
        <br>
        &copy; 2022
        <a href="https://yeyupiaoling.github.io">夜雨飘零</a>
        <a href="http://beian.miit.gov.cn" target="_blank">粤ICP备17019586号</a>
    </div>
    <span onclick="Util.goTop()" class="icon-goup"></span>
</footer>
<script>
  var Label = {
    speech: true,
    servePath: "https://yeyupiaoling.github.io",
    staticServePath: "https://yeyupiaoling.github.io",
    luteAvailable: false,
    hljsStyle: 'github',
    langLabel: "zh_CN",
    version: "4.3.1",
    staticSite: true,
    showCodeBlockLn: false,
    articleId: "1642598447430",
  }
</script>
<script src="https://yeyupiaoling.github.io/skins/yilia/js/common.min.js?1642833606409"></script>


<script type="text/javascript">
    Util.addScript('https://yeyupiaoling.github.io/js/page.min.js?1642833606409', 'soloPageScript')
    var page = new Page({
        "commentContentCannotEmptyLabel": "评论不能为空",
        "oId": "1642598447430",
        "blogHost": "https://yeyupiaoling.github.io",
        "randomArticles1Label": "随机阅读：",
        "externalRelevantArticles1Label": "站外相关阅读："
    });
    $(document).ready(function () {
        page.load();
        page.tips.externalRelevantArticlesDisplayCount = "0";
            page.loadRandomArticles();
            page.loadRelevantArticles('1642598447430', '<h4>相关阅读：</h4>');
        page.share()
    });
</script>
</main>
</body>
</html>

<!-- Generated by Latke (https://github.com/88250/latke) in 4ms, 2022/01/22 16:08:29 -->